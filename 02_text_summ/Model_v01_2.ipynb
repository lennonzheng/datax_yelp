{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Model_v01-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ca29be-3e64-4548-a224-bf91e2655c73"
      },
      "source": [
        "#make compatible with Python 2 and Python 3\n",
        "from __future__ import print_function, division, absolute_import\n",
        "\n",
        "# Remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "62ca29be-3e64-4548-a224-bf91e2655c73",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3604d5a-cd7c-4e43-aecd-a742ec6e9535",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32277292-dbbd-4245-f0dc-ca9ecccbda16"
      },
      "source": [
        "# regular expressions, text parsing, and ML classifiers\n",
        "import re\n",
        "import nltk\n",
        "import bs4 as bs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        " \n",
        "\n",
        "# download NLTK classifiers\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# import ml classifiers\n",
        "from nltk.tokenize import sent_tokenize # tokenizes sentences\n",
        "from nltk.stem import PorterStemmer     # parsing/stemmer\n",
        "from nltk.tag import pos_tag            # parts-of-speech tagging\n",
        "from nltk.corpus import wordnet         # sentiment scores\n",
        "from nltk.stem import WordNetLemmatizer # stem and context\n",
        "from nltk.corpus import stopwords       # stopwords\n",
        "from nltk.util import ngrams            # ngram iterator\n",
        "\n",
        "eng_stopwords = stopwords.words('english')"
      ],
      "id": "f3604d5a-cd7c-4e43-aecd-a742ec6e9535",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4a35a63-0df6-4e96-9c1a-79311a45b97d"
      },
      "source": [
        "## Process data"
      ],
      "id": "b4a35a63-0df6-4e96-9c1a-79311a45b97d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c032a7f5-604d-442a-a356-d368ae65b660"
      },
      "source": [
        "reviews_data = pd.read_csv('austin_review.csv')\n",
        "austin_rest = pd.read_csv('austin_rest.csv')"
      ],
      "id": "c032a7f5-604d-442a-a356-d368ae65b660",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf5PzvIvgj3h"
      },
      "source": [
        ""
      ],
      "id": "Hf5PzvIvgj3h"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57e0c1b9-1bcb-4897-aa6e-3fdb0f441b80"
      },
      "source": [
        "## takes in a resturant name (user inputs), or cusine type\n",
        "## match the Business id from resturant df to review df, get all reviews, and return a filtered review df\n",
        "\n",
        "def filter_reviews(rest_name, cusine=None, rest_df=austin_rest, rev_df=reviews_data):\n",
        "    rest_id = austin_rest.loc[austin_rest.name == rest_name].business_id.values[0]\n",
        "    train = rev_df.loc[reviews_data.business_id == rest_id]\n",
        "    return train"
      ],
      "id": "57e0c1b9-1bcb-4897-aa6e-3fdb0f441b80",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2549547d-420f-482c-8528-8c924d0bf29b"
      },
      "source": [
        "train = filter_reviews(\"Franklin Barbecue\")"
      ],
      "id": "2549547d-420f-482c-8528-8c924d0bf29b",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a74e440f-584b-4281-bbf2-b7bb202eadba"
      },
      "source": [
        "## Preparing data for classification"
      ],
      "id": "a74e440f-584b-4281-bbf2-b7bb202eadba"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIKUGpTzWff7"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "id": "KIKUGpTzWff7",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHc6Q4Ag_c3_"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "id": "rHc6Q4Ag_c3_",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fdd7ed4-8a8c-4fe4-b915-a71390fb48cc"
      },
      "source": [
        "def review_cleaner(review, lemmatize=True, stem=False):\n",
        "    '''\n",
        "        Clean and preprocess a review.\n",
        "            1. Remove HTML tags\n",
        "            2. Extract emoticons\n",
        "            3. Use regex to remove all special characters (only keep letters)\n",
        "            4. Make strings to lower case and tokenize / word split reviews\n",
        "            5. Remove English stopwords\n",
        "            6. Lemmatize\n",
        "            7. Rejoin to one string\n",
        "        \n",
        "        @review (type:str) is an unprocessed review string\n",
        "        @return (type:str) is a 6-step preprocessed review string\n",
        "    '''\n",
        "    \n",
        "    ps = PorterStemmer()\n",
        "    wnl = WordNetLemmatizer()\n",
        "\n",
        "    cleaned_reviews=[]\n",
        "    for i,review in enumerate(train['text']):\n",
        "        # batching step notification\n",
        "        if( (i+1)%1000 == 0 ):\n",
        "            print(\"Done with %d reviews\" %(i+1))\n",
        "        \n",
        "        \n",
        "        #1. Remove HTML tags\n",
        "        review = bs.BeautifulSoup(review).text    \n",
        "\n",
        "        #2. Use regex to find emoticons\n",
        "        emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', review)\n",
        "\n",
        "        #3. Remove punctuation\n",
        "        review = re.sub(\"[^a-zA-Z]\", \" \",review)\n",
        "\n",
        "        #4. Tokenize into words (all lower case)\n",
        "        review = review.lower().split()\n",
        "\n",
        "        #5. Remove stopwords\n",
        "        eng_stopwords = set(stopwords.words(\"english\"))\n",
        "        \n",
        "        #6. Lemmatize \n",
        "        clean_review=[]\n",
        "        for word in review:\n",
        "            if word not in eng_stopwords:\n",
        "                if lemmatize is True:\n",
        "                    word=wnl.lemmatize(word)\n",
        "                elif stem is True:\n",
        "                    if word == 'oed':\n",
        "                        continue\n",
        "                    word=ps.stem(word)\n",
        "                clean_review.append(word)\n",
        "\n",
        "        #7. Join the review to one sentence\n",
        "        review_processed = ' '.join(clean_review+emoticons)\n",
        "        cleaned_reviews.append(review_processed)\n",
        "    \n",
        "\n",
        "    return(cleaned_reviews)"
      ],
      "id": "4fdd7ed4-8a8c-4fe4-b915-a71390fb48cc",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "470606ca-ece9-4328-9bb3-ba63ba16310d"
      },
      "source": [
        "## Train and validate sentiment analysis model using Random Forest Classifier (RFC)"
      ],
      "id": "470606ca-ece9-4328-9bb3-ba63ba16310d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a8196a7-2452-4926-a8c3-09fae6befa7e"
      },
      "source": [
        "from sklearn import metrics                          # evaluating model\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#CountVectorizer can actucally handle a lot of the preprocessing for us\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# seed\n",
        "np.random.seed(0)"
      ],
      "id": "6a8196a7-2452-4926-a8c3-09fae6befa7e",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3abd8636-ac62-4282-a2af-2300121e05f7"
      },
      "source": [
        "def train_predict_sentiment(cleaned_reviews, y=train[\"stars\"], ngram=1, max_features=1000):\n",
        "    '''\n",
        "        This function will:\n",
        "            1. split data into train and test set.\n",
        "            2. get n-gram counts from cleaned reviews \n",
        "            3. train a random forest model using train n-gram counts and y (labels)\n",
        "            4. test the model on your test split\n",
        "            5. print accuracy of sentiment prediction on test and training data\n",
        "            6. print confusion matrix on test data results\n",
        "\n",
        "            To change n-gram type, set value of ngram argument\n",
        "            To change the number of features you want the countvectorizer to generate, set the value of max_features argument\n",
        "            \n",
        "            @cleaned_review (type:str) is preprocessed string from review_cleaner()\n",
        "            @return none\n",
        "    '''\n",
        "\n",
        "    print(\"Creating the bag of words model!\\n\")\n",
        "    # CountVectorizer\" is scikit-learn's bag of words tool, here we show more keywords \n",
        "    vectorizer = CountVectorizer(ngram_range=(1, ngram),\n",
        "                                 analyzer = \"word\",   \n",
        "                                 tokenizer = None,    \n",
        "                                 preprocessor = None, \n",
        "                                 stop_words = None,   \n",
        "                                 max_features = max_features) \n",
        "    \n",
        "    # train / test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(cleaned_reviews, y, random_state=0, test_size=.2)\n",
        "\n",
        "    # Then we use fit_transform() to fit the model / learn the vocabulary,\n",
        "    # then transform the data into feature vectors.\n",
        "    # The input should be a list of strings. .toarraty() converts to a numpy array\n",
        "    \n",
        "    train_bag = vectorizer.fit_transform(X_train).toarray()\n",
        "    test_bag = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "    print(\"Training the random forest classifier!\\n\")\n",
        "    # Initialize a Random Forest classifier with 50 trees\n",
        "    forest = RandomForestClassifier(n_estimators = 50) \n",
        "\n",
        "    # Fit the forest to the training set, using the bag of words as \n",
        "    # features and the sentiment labels as the target variable\n",
        "    forest = forest.fit(train_bag, y_train)\n",
        "\n",
        "    # predict\n",
        "    train_predictions = forest.predict(train_bag)\n",
        "    test_predictions = forest.predict(test_bag)\n",
        "    \n",
        "    # validation\n",
        "    train_acc = metrics.accuracy_score(y_train, train_predictions)\n",
        "    valid_acc = metrics.accuracy_score(y_test, test_predictions)\n",
        "    \n",
        "    print(\" The training accuracy is: \", train_acc, \"\\n\", \"The validation accuracy is: \", valid_acc)\n",
        "    print()\n",
        "    print('CONFUSION MATRIX:')\n",
        "    print('         Predicted')\n",
        "    print('          neg pos')\n",
        "    print(' Actual')\n",
        "    c=confusion_matrix(y_test, test_predictions)\n",
        "    print('     neg  ',c[0])\n",
        "    print('     pos  ',c[1])\n",
        "\n",
        "    #Extract feature importance\n",
        "    print('\\nTOP TEN IMPORTANT FEATURES:')\n",
        "    importances = forest.feature_importances_\n",
        "    indices = np.argsort(importances)[::-1]\n",
        "    top_10 = indices[:20]\n",
        "    print([vectorizer.get_feature_names()[ind] for ind in top_10])"
      ],
      "id": "3abd8636-ac62-4282-a2af-2300121e05f7",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aef3d3e-5637-4fbf-8327-dfbb3aacf5fe"
      },
      "source": [
        "## Train and test  Model"
      ],
      "id": "9aef3d3e-5637-4fbf-8327-dfbb3aacf5fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b80eab1-be7c-4c3c-8379-9bf587c2123d"
      },
      "source": [
        "<br>\n",
        "\n",
        "**Preprocess data**"
      ],
      "id": "0b80eab1-be7c-4c3c-8379-9bf587c2123d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3711a158-18ee-4947-ba03-abe87178f7f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ad55cf-7132-4fbf-9ff9-24b840fcf8de"
      },
      "source": [
        "# Clean the reviews in the training set 'train' using review_cleaner function defined above\n",
        "# Here we use the original reviews without lemmatizing and stemming\n",
        "original_clean_reviews_lemmatize = review_cleaner(train['text'], lemmatize=True, stem=False)"
      ],
      "id": "3711a158-18ee-4947-ba03-abe87178f7f9",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done with 1000 reviews\n",
            "Done with 2000 reviews\n",
            "Done with 3000 reviews\n",
            "Done with 4000 reviews\n",
            "Done with 5000 reviews\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21e462ce-e76c-4e84-b3e9-54e316310ff1"
      },
      "source": [
        "<br>\n",
        "\n",
        "**Train RFC**"
      ],
      "id": "21e462ce-e76c-4e84-b3e9-54e316310ff1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "253e9770-9c8a-4439-9a6c-5f48df629c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753ac139-38e8-42ed-9826-a5542b8e1558"
      },
      "source": [
        "train_predict_sentiment(cleaned_reviews=original_clean_reviews_lemmatize, y=train[\"stars\"], ngram=2, max_features=1000)"
      ],
      "id": "253e9770-9c8a-4439-9a6c-5f48df629c49",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the bag of words model!\n",
            "\n",
            "Training the random forest classifier!\n",
            "\n",
            " The training accuracy is:  0.9995069033530573 \n",
            " The validation accuracy is:  0.7438423645320197\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "         Predicted\n",
            "          neg pos\n",
            " Actual\n",
            "     neg   [ 1  0  0  0 23]\n",
            "     pos   [ 0  0  1  1 27]\n",
            "\n",
            "TOP TEN IMPORTANT FEATURES:\n",
            "['brisket', 'good', 'better', 'line', 'best', 'wait', 'bbq', 'ever', 'hour', 'star', 'franklin', 'food', 'rib', 'long', 'place', 'meat', 'would', 'get', 'time', 'pretty good']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAOOLmLJ7-CG",
        "outputId": "44bce6be-fa94-4ce6-feb9-0944f8ded794"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "#have to pip install geopandas in terminal before importing \n",
        "#have to pip install haversine in terminal before importing\n",
        "!pip install haversine \n",
        "from haversine import haversine, Unit"
      ],
      "id": "MAOOLmLJ7-CG",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: haversine in /usr/local/lib/python3.7/dist-packages (2.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "y2F9RL_d7-Mv",
        "outputId": "03790445-d74b-4988-c750-30b9c9a759cf"
      },
      "source": [
        "### creating closest restaurants algorithm\n",
        "#will be using data cleaned from before, open_restaurants\n",
        "restaurants = pd.read_csv('open_restaurants.csv')\n",
        "restaurants = restaurants.drop('is_open', axis = 1)\n",
        "restaurants.head(5)"
      ],
      "id": "y2F9RL_d7-Mv",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>name</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_count</th>\n",
              "      <th>attributes</th>\n",
              "      <th>categories</th>\n",
              "      <th>hours</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NRPemqVb4qpWFF0Avq_6OQ</td>\n",
              "      <td>Eurasia Sushi Bar &amp; Seafood</td>\n",
              "      <td>30.234533</td>\n",
              "      <td>-97.877262</td>\n",
              "      <td>4.5</td>\n",
              "      <td>395</td>\n",
              "      <td>{'Ambience': \"{'touristy': False, 'hipster': F...</td>\n",
              "      <td>Bars, Nightlife, Cocktail Bars, Seafood, Resta...</td>\n",
              "      <td>{'Monday': '0:0-0:0', 'Tuesday': '11:0-22:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>bRsDZ44CD3uhGnRY3NeQhQ</td>\n",
              "      <td>Wendy's</td>\n",
              "      <td>30.441875</td>\n",
              "      <td>-97.746581</td>\n",
              "      <td>2.0</td>\n",
              "      <td>46</td>\n",
              "      <td>{'RestaurantsPriceRange2': '1', 'OutdoorSeatin...</td>\n",
              "      <td>Fast Food, Restaurants, Burgers</td>\n",
              "      <td>{'Monday': '6:30-1:0', 'Tuesday': '6:30-1:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Pk4ZwXwUU50BDn5gqw_rKg</td>\n",
              "      <td>Johnny Carino's</td>\n",
              "      <td>30.162081</td>\n",
              "      <td>-97.789132</td>\n",
              "      <td>3.0</td>\n",
              "      <td>136</td>\n",
              "      <td>{'RestaurantsGoodForGroups': 'True', 'Business...</td>\n",
              "      <td>Italian, Salad, Pizza, Nightlife, Restaurants,...</td>\n",
              "      <td>{'Monday': '11:0-21:30', 'Tuesday': '11:0-21:3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>Ieelu69Y23nbjKG3OGfwnw</td>\n",
              "      <td>McDonald's</td>\n",
              "      <td>30.232133</td>\n",
              "      <td>-97.823183</td>\n",
              "      <td>1.5</td>\n",
              "      <td>9</td>\n",
              "      <td>{'RestaurantsTakeOut': 'True', 'RestaurantsRes...</td>\n",
              "      <td>Restaurants, Coffee &amp; Tea, Food, Burgers, Fast...</td>\n",
              "      <td>{'Monday': '7:0-22:30', 'Tuesday': '7:0-22:30'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>IFB2K3BEZ2L_Mv5AbUD26Q</td>\n",
              "      <td>Chispas</td>\n",
              "      <td>30.266996</td>\n",
              "      <td>-97.745362</td>\n",
              "      <td>3.5</td>\n",
              "      <td>119</td>\n",
              "      <td>{'RestaurantsTakeOut': 'True', 'OutdoorSeating...</td>\n",
              "      <td>Tex-Mex, Mexican, Tacos, Restaurants</td>\n",
              "      <td>{'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                              hours\n",
              "0           1  ...  {'Monday': '0:0-0:0', 'Tuesday': '11:0-22:0', ...\n",
              "1           2  ...  {'Monday': '6:30-1:0', 'Tuesday': '6:30-1:0', ...\n",
              "2           5  ...  {'Monday': '11:0-21:30', 'Tuesday': '11:0-21:3...\n",
              "3           6  ...  {'Monday': '7:0-22:30', 'Tuesday': '7:0-22:30'...\n",
              "4           7  ...  {'Monday': '11:0-22:0', 'Tuesday': '11:0-22:0'...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h6TeSe77-SG",
        "outputId": "0e5eff4b-307a-4842-9272-6bd6d3a57744"
      },
      "source": [
        "#given a restaurant, want to create a list of restaurants within a given mile radius\n",
        "#or rather a list of 10 closest restaurants\n",
        "# will use imported haversine formula in form haversine((lat1, long1), (lat2, long2))\n",
        "practice = 'Pk4ZwXwUU50BDn5gqw_rKg'\n",
        "lat1 = restaurants[restaurants['business_id']==practice]['latitude']\n",
        "long1 = restaurants[restaurants['business_id']==practice]['longitude']\n",
        "\n",
        "coord1 = (lat1, long1)\n",
        "\n",
        "practice2 = 'fTgnVCCu6k_Ds25Nz73s5Q'\n",
        "lat2 = restaurants[restaurants['business_id']==practice2]['latitude']\n",
        "long2 = restaurants[restaurants['business_id']==practice2]['longitude']\n",
        "\n",
        "coord2 = (lat2, long2)\n",
        "haversine(coord1, coord2, unit = 'mi')"
      ],
      "id": "2h6TeSe77-SG",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.882687089753406"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjCmzYL87-Vn"
      },
      "source": [
        "# given business_id of restaurant return closest restaurants\n",
        "# takes in business ID and integer of restaurants selected (5 or 10)\n",
        "def closest_restaurants(business_ID, int seleted):\n",
        "    counter = 0\n",
        "    restaurant_list = []\n",
        "    lat1 = restaurants[restaurants['business_id'] == business_ID]['latitude']\n",
        "    long1 = restaurants[restaurants['business_id']== business_ID]['longitude']\n",
        "    business_coord = (lat1, long1)\n",
        "    remaining_IDs = list(restaurants[restaurants['business_id'] != business_ID]['business_id'])\n",
        "    for ID in remaining_IDs:\n",
        "        lat2 = restaurants[restaurants['business_id'] == ID]['latitude']\n",
        "        long2 = restaurants[restaurants['business_id']== ID]['longitude']\n",
        "        i_coord = (lat2, long2)\n",
        "        #unit = 'mi' ensures distance is given in miles\n",
        "        dist = haversine(business_coord, i_coord, unit = 'mi')\n",
        "        if counter < selected:\n",
        "            restaurant_list.append(ID)\n",
        "        elif counter > selected:\n",
        "            for i in range(0, selected):\n",
        "                lat3 = restaurants[restaurants['business_id'] == restaurant_list[i]]['latitude']\n",
        "                long3 = restaurants[restaurants['business_id']== restaurant_list[i]]['longitude']\n",
        "                i_coord2 = (lat3, long3)\n",
        "                i_dist = haversine(business_coord, i_coord2, unit = 'mi')\n",
        "                if dist < i_dist:\n",
        "                    restaurant_list[i] = ID\n",
        "                    break\n",
        "        counter += 1\n",
        "    return restaurant_list"
      ],
      "id": "CjCmzYL87-Vn",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMgxX8w-8RlV"
      },
      "source": [
        ""
      ],
      "id": "KMgxX8w-8RlV",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aiN9tpl8Rpf"
      },
      "source": [
        ""
      ],
      "id": "_aiN9tpl8Rpf",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4febb04-0f4b-4492-9c5c-f8eb54e55be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "3cfe4c6b-843a-4b22-ff72-dcd10adf5bf0"
      },
      "source": [
        "pip install anvil-uplink"
      ],
      "id": "e4febb04-0f4b-4492-9c5c-f8eb54e55be6",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anvil-uplink in /usr/local/lib/python3.7/dist-packages (0.3.40)\n",
            "Collecting argparse\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Requirement already satisfied: ws4py in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.5.1)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tZY_RDniY1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e1887c-1d4c-47be-e1f0-e9bbeeb4b88d"
      },
      "source": [
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"YIXTXTLMQSSUKJTGS4UCCS7G-NXLX35O2PI46VEKK\")"
      ],
      "id": "8tZY_RDniY1z",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default environment\" as SERVER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "4zy28F0J-jk6",
        "outputId": "38447bbd-808b-46c6-aad2-6897de3a9b07"
      },
      "source": [
        "lister = closest_restaurants('IFB2K3BEZ2L_Mv5AbUD26Q')\n",
        "restaurants[restaurants['business_id'].isin(lister)]"
      ],
      "id": "4zy28F0J-jk6",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>business_id</th>\n",
              "      <th>name</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>stars</th>\n",
              "      <th>review_count</th>\n",
              "      <th>attributes</th>\n",
              "      <th>categories</th>\n",
              "      <th>hours</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>828</td>\n",
              "      <td>LE46JAgAQ6zLsotQ17i8Mg</td>\n",
              "      <td>Fourth &amp; CO</td>\n",
              "      <td>30.266980</td>\n",
              "      <td>-97.745256</td>\n",
              "      <td>4.0</td>\n",
              "      <td>17</td>\n",
              "      <td>{'BikeParking': 'True', 'WheelchairAccessible'...</td>\n",
              "      <td>Cocktail Bars, Nightlife, Chicken Wings, Resta...</td>\n",
              "      <td>{'Monday': '16:0-2:0', 'Tuesday': '16:0-2:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>3487</td>\n",
              "      <td>4-RkxDM200qfSG756uVmtQ</td>\n",
              "      <td>Péché</td>\n",
              "      <td>30.266980</td>\n",
              "      <td>-97.745256</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1135</td>\n",
              "      <td>{'GoodForKids': 'False', 'RestaurantsGoodForGr...</td>\n",
              "      <td>Nightlife, Lounges, Cocktail Bars, Restaurants...</td>\n",
              "      <td>{'Monday': '17:0-2:0', 'Tuesday': '17:0-2:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2285</th>\n",
              "      <td>3981</td>\n",
              "      <td>GZfHsTQAabxdXB_z30h6kw</td>\n",
              "      <td>DeSano Pizzeria Napoletana</td>\n",
              "      <td>30.266160</td>\n",
              "      <td>-97.745872</td>\n",
              "      <td>4.5</td>\n",
              "      <td>124</td>\n",
              "      <td>{'BusinessAcceptsCreditCards': 'True', 'DogsAl...</td>\n",
              "      <td>Italian, Pizza, Restaurants</td>\n",
              "      <td>{'Monday': '0:0-0:0', 'Tuesday': '11:30-22:0',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2401</th>\n",
              "      <td>4185</td>\n",
              "      <td>9al-eBiJVbuhuFzzuQpiSQ</td>\n",
              "      <td>Gloria's Latin Cuisine</td>\n",
              "      <td>30.268909</td>\n",
              "      <td>-97.745333</td>\n",
              "      <td>3.5</td>\n",
              "      <td>348</td>\n",
              "      <td>{'BusinessParking': \"{'garage': True, 'street'...</td>\n",
              "      <td>Mexican, Latin American, Salvadoran, Tex-Mex, ...</td>\n",
              "      <td>{'Monday': '0:0-0:0', 'Tuesday': '11:0-21:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>4374</td>\n",
              "      <td>pCIdgI3QYpzgrtLAmDemuA</td>\n",
              "      <td>Truluck’s Ocean’s Finest Seafood and Crab</td>\n",
              "      <td>30.266884</td>\n",
              "      <td>-97.744980</td>\n",
              "      <td>4.5</td>\n",
              "      <td>843</td>\n",
              "      <td>{'BusinessParking': \"{'garage': False, 'street...</td>\n",
              "      <td>Restaurants, Buffets, Seafood, Steakhouses</td>\n",
              "      <td>{'Monday': '0:0-0:0', 'Tuesday': '16:30-21:0',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>4497</td>\n",
              "      <td>NL_Tg1VV5d9iztDqBrw5jQ</td>\n",
              "      <td>Jessica's Original Cheesesteak</td>\n",
              "      <td>30.267197</td>\n",
              "      <td>-97.744789</td>\n",
              "      <td>2.5</td>\n",
              "      <td>14</td>\n",
              "      <td>{'BusinessAcceptsCreditCards': 'True', 'Restau...</td>\n",
              "      <td>Sandwiches, Restaurants, Food, Street Vendors</td>\n",
              "      <td>{'Monday': '11:0-14:0', 'Tuesday': '11:0-14:0'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2608</th>\n",
              "      <td>4547</td>\n",
              "      <td>74ZOTBit9H9Z_YAP7YaE1Q</td>\n",
              "      <td>Manuel's</td>\n",
              "      <td>30.265578</td>\n",
              "      <td>-97.743707</td>\n",
              "      <td>3.5</td>\n",
              "      <td>568</td>\n",
              "      <td>{'GoodForKids': 'True', 'RestaurantsGoodForGro...</td>\n",
              "      <td>Restaurants, Mexican, Breakfast &amp; Brunch</td>\n",
              "      <td>{'Monday': '0:0-0:0', 'Tuesday': '11:0-21:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2620</th>\n",
              "      <td>4568</td>\n",
              "      <td>c-6SPBhWeA0xFrbnM0sjJg</td>\n",
              "      <td>Chi'Lantro</td>\n",
              "      <td>30.265830</td>\n",
              "      <td>-97.744641</td>\n",
              "      <td>4.5</td>\n",
              "      <td>6</td>\n",
              "      <td>{'RestaurantsTakeOut': 'True', 'RestaurantsDel...</td>\n",
              "      <td>Korean, Barbeque, Restaurants</td>\n",
              "      <td>{'Monday': '7:0-15:0', 'Tuesday': '7:0-15:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2735</th>\n",
              "      <td>4774</td>\n",
              "      <td>2vppZx0rTDZtCzw-NljdRQ</td>\n",
              "      <td>The Capital Grille</td>\n",
              "      <td>30.266248</td>\n",
              "      <td>-97.744589</td>\n",
              "      <td>4.0</td>\n",
              "      <td>338</td>\n",
              "      <td>{'Ambience': \"{'romantic': False, 'intimate': ...</td>\n",
              "      <td>Wine Bars, Bars, Nightlife, American (Traditio...</td>\n",
              "      <td>{'Monday': '0:0-0:0', 'Tuesday': '11:0-21:0', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2768</th>\n",
              "      <td>4844</td>\n",
              "      <td>Fjt54fSz56goWef5n42HWA</td>\n",
              "      <td>Shiner's Saloon</td>\n",
              "      <td>30.267036</td>\n",
              "      <td>-97.743559</td>\n",
              "      <td>4.0</td>\n",
              "      <td>176</td>\n",
              "      <td>{'RestaurantsGoodForGroups': 'True', 'NoiseLev...</td>\n",
              "      <td>Restaurants, American (Traditional), Nightlife...</td>\n",
              "      <td>{'Monday': '16:0-2:0', 'Tuesday': '16:0-2:0', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...                                              hours\n",
              "480          828  ...  {'Monday': '16:0-2:0', 'Tuesday': '16:0-2:0', ...\n",
              "2002        3487  ...  {'Monday': '17:0-2:0', 'Tuesday': '17:0-2:0', ...\n",
              "2285        3981  ...  {'Monday': '0:0-0:0', 'Tuesday': '11:30-22:0',...\n",
              "2401        4185  ...  {'Monday': '0:0-0:0', 'Tuesday': '11:0-21:0', ...\n",
              "2499        4374  ...  {'Monday': '0:0-0:0', 'Tuesday': '16:30-21:0',...\n",
              "2575        4497  ...  {'Monday': '11:0-14:0', 'Tuesday': '11:0-14:0'...\n",
              "2608        4547  ...  {'Monday': '0:0-0:0', 'Tuesday': '11:0-21:0', ...\n",
              "2620        4568  ...  {'Monday': '7:0-15:0', 'Tuesday': '7:0-15:0', ...\n",
              "2735        4774  ...  {'Monday': '0:0-0:0', 'Tuesday': '11:0-21:0', ...\n",
              "2768        4844  ...  {'Monday': '16:0-2:0', 'Tuesday': '16:0-2:0', ...\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFC8SQziBixd",
        "outputId": "373df74f-0549-478b-a2be-313f9796977e"
      },
      "source": [
        "s = pd.Series(restaurants[restaurants['business_id'].isin(lister)]['name'])\n",
        "for value in s.items():\n",
        "  print(value[1])"
      ],
      "id": "zFC8SQziBixd",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fourth & CO\n",
            "Péché\n",
            "DeSano Pizzeria Napoletana\n",
            "Gloria's Latin Cuisine\n",
            "Truluck’s Ocean’s Finest Seafood and Crab\n",
            "Jessica's Original Cheesesteak\n",
            "Manuel's\n",
            "Chi'Lantro\n",
            "The Capital Grille\n",
            "Shiner's Saloon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BSKGyV4jNkS"
      },
      "source": [
        "@anvil.server.callable\n",
        "def find_competitors(text):\n",
        "  selected_id = restaurants[restaurants['name'] == text]['business_id'].item()\n",
        "  closest_ids = closest_restaurants(selected_id, 10)\n",
        "  competitor_series = restaurants[restaurants['business_id'].isin(closest_ids)]['name']\n",
        "  s = pd.Series(competitor_series)\n",
        "  lister = []\n",
        "  for value in s.items():\n",
        "    lister = np.append(lister, value[1])\n",
        "\n",
        "  return lister\n",
        "    \n"
      ],
      "id": "4BSKGyV4jNkS",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6d-eo2nkoeB"
      },
      "source": [
        "s"
      ],
      "id": "-6d-eo2nkoeB",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifi1HczHylFm"
      },
      "source": [
        ""
      ],
      "id": "ifi1HczHylFm",
      "execution_count": 39,
      "outputs": []
    }
  ]
}